## TODOLIST
1. 写一个篇章切分，把篇章切分成若干个 [Done]
2. 封装预测功能 [Done]
3. 写一个根据关键词标注unlabeled_data的程序
4. 把预测的序列变成多个，然后综合每个预测结果做出最终预测 [Done]
5. 对篇章关键词抽取 / ... 等可能有用的方法， 然后建图，做谱聚类 (好像很难写...)
6. ~~貌似把篇章划分成多个训练不是很理想的样子...(感觉,还没实践)~~

## GROUND_TRUTH
1. unlabeled_data的预标注种类个数\
NULL    18409 \
游戏     3227 \
娱乐     2640 \
科技     2373 \
房产     2207 \
家居     1650 \
时尚     1042 \
体育      714 \
教育      382 \
财经      183 \
时政      173 
2. confusion矩阵:即测试的时候预测的正确与否的矩阵 \
[[849  10  21   2   7   0  17  26   1  67] \
 [ 16 640  16   0  64   0   7   3   6 248] \
 [ 12  90 779   0   2   3   8  61   2  43] \
 [  1   0   0 511   1   1 319 134   0  33] \
 [  0  81 156   4 478   4  35  17  17 208] \
 [  0   1   2   2   0 757  96   9   5 128] \
 [  1   1   1   6   9   3 926   8   0  45] \
 [  3  10  41   0   7   1  25 876   1  36] \
 [  0   4   0   0   6   0 534   0 449   7] \
 [  0   2   0   1   2   7 338   0  10 640]]

3. metrics

Test Loss:   1.0,  Test Acc: 69.05% \
Precision, Recall and F1-Score... 
         
                 precision    recall  f1-score   support

          财经     0.9626    0.8490    0.9022      1000
          时政     0.7628    0.6400    0.6960      1000
          房产     0.7667    0.7790    0.7728      1000
          科技     0.9715    0.5110    0.6697      1000
          教育     0.8299    0.4780    0.6066      1000
          时尚     0.9755    0.7570    0.8525      1000
          游戏     0.4017    0.9260    0.5604      1000
          家居     0.7725    0.8760    0.8210      1000
          体育     0.9145    0.4490    0.6023      1000
          娱乐     0.4399    0.6400    0.5214      1000

    accuracy                             0.6905     10000
    macro avg        0.7798    0.6905    0.7005     10000
    weighted avg     0.7798    0.6905    0.7005     10000


## IDEA
1. 这样切分多段可能会导致信息不完整 或者 具有噪声等误导信息
2. fasttext文本预分类可能不准确
3. 根据confusion矩阵来分析的话..F1值比较低的有 娱乐/时政/游戏.
	而且预标签的时候，我发现有些娱乐/游戏很难区分...
4. 看到了游戏/娱乐/体育这三类占得比例不太一样...所以训练集/验证集不平衡可能也是问题之一..
5. 科技、教育、体育、时政的recall很低也就是查全率很低... 但是游戏的查全率很高，非常非常可能是
 游戏占比太大太大了.. 所以还是数据集占比问题 qwq

## METHOD
1. baseline:直接把篇章不做任何处理丢进去
2. cut_paras:切割好之后，把若干个切割好的预测结果综合起来，\
	这里分为三种: (1)投票(2)softmax求和(3)求和...\
	目前来看(1)最好，结果是0.73

## README
这里写一下大概的步骤，方便使用的人阅读..\
不过有点懒得自己模拟一遍了，所以靠回忆来写。。
如果存在什么问题还是可以戳我..

之前开源的项目已经封装好了BERT的加载/fine_tuning部分，并且也已经加了一个(HIDDEN_LAYER, CLASS_SIZE)的全连接层用于输出。之前已经完成了训练、验证、测试部分，所以我们只需要把数据处理成他的格式就可以直接跑，但是他没有把预测label功能封装起来，所以这里我自己写了个预测label的功能，加上一些数据处理的部分等等。

因为题目给的训练集包含的标签不全，所以需要预标注一些unlabeled数据

pre_label.py : 利用fasttext对unlabeled_data进行预标注，并且将这些预标注的数据和已经标注好的数据合并放到real/data/labeled_data_with_10_classes.csv相当于一个标签完整的数据集。

real/data/generate_data.py : 将有10类的数据集分割成训练集和验证集，利用外部数据做测试（只是看效果，应该不算利用外部数据把...）。这里的做法是把一些长的篇章切割成若干个短的篇章进行训练，因为如果不切割的话，每次只能看到篇章的前128个字符。这里只做了标点删除处理，没有管"的、了，地"等等无实际意思的词。这样处理可能会造成噪声大？不太清楚，感觉这个地方还可以提升。

predict.py : 封装了预测功能，暂时实现了两个方法

你要跑通项目可能先要下载数据集和模型，然后prelabel一下，再生成符合项目格式的数据(generate_data)，最后再predict
